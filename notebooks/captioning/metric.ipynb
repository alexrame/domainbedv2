{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import collections\n",
    "import numpy as np\n",
    "# sys.path.append(\"/private/home/alexandrerame/domainbedv2/\")\n",
    "# sys.path.append(\"/private/home/alexandrerame/slurmconfig/notebook/data\")\n",
    "\n",
    "sys.path.append(\"/home/rame/domainbedv2/\")\n",
    "sys.path.append(\"/home/rame/ExpansionNet_v2//\")\n",
    "\n",
    "from domainbed.codeplot import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.meteor.meteor import Meteor\n",
    "from eval.meteor.reinforce_meteor import Meteor as ReinforceMeteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from eval.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "\n",
    "from nltk.tokenize.stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '''Good muffins cost $3.88\\nin New York,  Please buy me\\ntwo of them.\\nThanks.'''\n",
    "gts = {1: [{\"caption\": s}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['good muffins cost $ 3.88 in new york please buy me two of them thanks']}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PTBTokenizer()\n",
    "print(tokenizer.tokenize(gts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATIONS = [\"''\", \"'\", \"``\", \"`\", \"-LRB-\", \"-RRB-\", \"-LCB-\", \"-RCB-\", \\\n",
    "        \".\", \"?\", \"!\", \",\", \":\", \"-\", \"--\", \"...\", \";\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.tokenizer.pythontokenizer import PythonTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NLTK tokenizer\n",
      "{1: ['good muffins cost $ 3.88 in new york please buy me two of them thanks']}\n"
     ]
    }
   ],
   "source": [
    "pt = PythonTokenizer()\n",
    "print(pt.tokenize(gts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts_final_tokenized_captions_for_image = {}\n",
    "for k, vs in gts.items():\n",
    "    if not k in gts_final_tokenized_captions_for_image:\n",
    "        gts_final_tokenized_captions_for_image[k] = []\n",
    "    for v in vs:\n",
    "        tokenized_caption = \" \".join(t.tokenize(v['caption']))\n",
    "        tokenized_caption = ' '.join([w for w in tokenized_caption if w not in PUNCTUATIONS]).lower()\n",
    "        gts_final_tokenized_captions_for_image[k].append(tokenized_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['good muffins cost $ 3.88 in new york please buy me two of them. thanks']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts_final_tokenized_captions_for_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'muffins',\n",
       " 'cost',\n",
       " '$',\n",
       " '3.88',\n",
       " 'in',\n",
       " 'New',\n",
       " 'York.',\n",
       " 'Please',\n",
       " 'buy',\n",
       " 'me',\n",
       " 'two',\n",
       " 'of',\n",
       " 'them.',\n",
       " 'Thanks',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TreebankWordTokenizer()\n",
    "t.tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/rame/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'orm.weight/bias'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"swin_transf.norm.weight/bias\".lstrip(\"swin_transf.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/rame/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6233062330623306"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.translate.meteor_score.meteor_score(\n",
    "    [\"this is an apple\".split(\" \"), \"that is an apple\".split(\" \")],\n",
    "    \"an apple on this tree\".split(\" \")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meteor(reference, hypothesis, alpha=0.5):\n",
    "    reference_unigrams = Counter(reference.split())\n",
    "    hypothesis_unigrams = Counter(hypothesis.split())\n",
    "    reference_bigrams = Counter(zip(reference.split()[:-1], reference.split()[1:]))\n",
    "    hypothesis_bigrams = Counter(zip(hypothesis.split()[:-1], hypothesis.split()[1:]))\n",
    "\n",
    "    precision = (\n",
    "        alpha * precision_n(reference_unigrams, hypothesis_unigrams, 1) +\n",
    "        (1 - alpha) * precision_n(reference_bigrams, hypothesis_bigrams, 2)\n",
    "    )\n",
    "    recall = (\n",
    "        alpha * recall_n(reference_unigrams, hypothesis_unigrams, 1) +\n",
    "        (1 - alpha) * recall_n(reference_bigrams, hypothesis_bigrams, 2)\n",
    "    )\n",
    "\n",
    "    if precision == 0 or recall == 0:\n",
    "        return 0\n",
    "\n",
    "    harmonic_mean = (1 / precision + 1 / recall) / 2\n",
    "    unigram_penalty = 0.5 * (1 - len(reference_unigrams) / len(hypothesis_unigrams))\n",
    "\n",
    "    meteor_score = harmonic_mean * (1 - unigram_penalty)\n",
    "\n",
    "    return meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_n(reference, hypothesis, n):\n",
    "    if not hypothesis:\n",
    "        return 0\n",
    "\n",
    "    intersection = 0\n",
    "    for ngram in hypothesis:\n",
    "        if ngram in reference:\n",
    "            intersection += 1\n",
    "    return intersection / len(hypothesis)\n",
    "\n",
    "\n",
    "def recall_n(reference, hypothesis, n):\n",
    "    if not reference:\n",
    "        return 0\n",
    "\n",
    "    intersection = 0\n",
    "    for ngram in hypothesis:\n",
    "        if ngram in reference:\n",
    "            intersection += 1\n",
    "    return intersection / len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meteor:\n",
    "\n",
    "    def __init__(self):\n",
    "        # vrama91: updated the value below based on discussion with Hovey\n",
    "        self.alpha = 0.5\n",
    "\n",
    "    def calc_score(self, hypo, refs):\n",
    "        score = 0\n",
    "        for ref in refs:\n",
    "            score += meteor(reference=ref, hypothesis=hypo, alpha=self.alpha)\n",
    "        return score / len(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Meteor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.17710407239819"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.calc_score(\n",
    "    refs=[\"this is an apple\", \"that is an apple\"],\n",
    "    hypo=\"an apple on this tree\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
