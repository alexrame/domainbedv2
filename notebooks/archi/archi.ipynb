{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import gradio as gr\n",
    "from random import shuffle\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = Path(\"/data/rame/experiments/archi/\")\n",
    "# finetuned = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"architext/gptj-162M\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-j-6B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_images(im1, im2):\n",
    "    images = [im1, im2]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    combined = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        combined.paste(im, (x_offset,0))\n",
    "        x_offset += im.size[0]\n",
    "    return combined\n",
    "\n",
    "room_labels = {\"living_room\": 1, \"kitchen\": 2, \"bedroom\": 3, \"bathroom\": 4, \"missing\": 5, \"closet\": 6, \n",
    "                         \"balcony\": 7, \"corridor\": 8, \"dining_room\": 9, \"laundry_room\": 10}\n",
    "\n",
    "architext_colors = [[0, 0, 0], [249, 222, 182], [195, 209, 217], [250, 120, 128], [126, 202, 234], [190, 0, 198], [255, 255, 255], \n",
    "                   [6, 53, 17], [17, 33, 58], [132, 151, 246], [197, 203, 159], [6, 53, 17],]\n",
    "\n",
    "regex = re.compile(\".*?\\((.*?)\\)\")\n",
    "\n",
    "def draw_polygons(polygons, colors, im_size=(256, 256), b_color=\"white\", fpath=None):\n",
    "\n",
    "    image = Image.new(\"RGB\", im_size, color=\"white\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for poly, color, in zip(polygons, colors):\n",
    "        xy = poly.exterior.xy\n",
    "        coords = np.dstack((xy[1], xy[0])).flatten()\n",
    "        draw.polygon(list(coords), fill=(0, 0, 0))       \n",
    "        \n",
    "        #get inner polygon coordinates\n",
    "        small_poly = poly.buffer(-1, resolution=32, cap_style=2, join_style=2, mitre_limit=5.0)\n",
    "        if small_poly.geom_type == 'MultiPolygon':\n",
    "            mycoordslist = [list(x.exterior.coords) for x in small_poly]\n",
    "            for coord in mycoordslist:\n",
    "                coords = np.dstack((np.array(coord)[:,1], np.array(coord)[:, 0])).flatten()\n",
    "                draw.polygon(list(coords), fill=tuple(color)) \n",
    "        elif poly.geom_type == 'Polygon':\n",
    "            #get inner polygon coordinates\n",
    "            xy2 = small_poly.exterior.xy\n",
    "            coords2 = np.dstack((xy2[1], xy2[0])).flatten()\n",
    "            # draw it on canvas, with the appropriate colors\n",
    "            draw.polygon(list(coords2), fill=tuple(color)) \n",
    "\n",
    "    #image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "    if(fpath):\n",
    "        image.save(fpath, format='png', quality=100, subsampling=0)\n",
    "        np.save(fpath, np.array(image))\n",
    "\n",
    "    return draw, image\n",
    "\n",
    "def prompt_to_layout(user_prompt, fpath=None):\n",
    "    \n",
    "    model_prompt = '[User prompt] {} [Layout]'.format(user_prompt)\n",
    "    input_ids = tokenizer(model_prompt, return_tensors='pt')\n",
    "    output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, top_k=100, max_length=300)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    \n",
    "    layout = output[0].split('[User prompt]')[1].split('[Layout]')[1].split(', ')\n",
    "    spaces = [txt.split(':')[0].lstrip() for txt in layout]\n",
    "    spaces = [re.sub(r'\\d+', '', s) for s in spaces]\n",
    "\n",
    "    coordinates = [txt.split(':')[1] for txt in layout]\n",
    "    coordinates = [re.findall(regex, coord) for coord in coordinates]\n",
    "    \n",
    "    polygons = []\n",
    "    for coord in coordinates:\n",
    "        polygons.append([point.split(',') for point in coord])\n",
    "        \n",
    "    geom = []\n",
    "    for poly in polygons:\n",
    "        geom.append(Polygon(np.array(poly, dtype=int)))\n",
    "        \n",
    "    colors = [architext_colors[room_labels[space]] for space in spaces]\n",
    "    \n",
    "    _, im = draw_polygons(geom, colors, fpath=fpath)\n",
    "    \n",
    "    legend = Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/legend.png\")\n",
    "    \n",
    "    im_new = Image.new('RGB', (256, 296))\n",
    "    im_new.paste(legend, (0, 0))\n",
    "    im_new.paste(im, (0, 40))\n",
    "    \n",
    "    return im_new, layout, output\n",
    "\n",
    "def mut_txt2layout(mut_output):\n",
    "    layout = mut_output[0].split('[User prompt]')[1].split('[Layout]')[1].split(', ')\n",
    "    spaces = [txt.split(':')[0].lstrip() for txt in layout]\n",
    "    spaces = [re.sub(r'\\d+', '', s) for s in spaces]\n",
    "    coordinates = [txt.split(':')[1] for txt in layout]\n",
    "    coordinates = [re.findall(regex, coord) for coord in coordinates]\n",
    "\n",
    "    polygons = []\n",
    "    for coord in coordinates:\n",
    "        polygons.append([point.split(',') for point in coord])\n",
    "\n",
    "    geom = []\n",
    "    for poly in polygons:\n",
    "        geom.append(Polygon(np.array(poly, dtype=int)))\n",
    "\n",
    "    colors = [architext_colors[room_labels[space]] for space in spaces]\n",
    "    _, im = draw_polygons(geom, colors, fpath=None)\n",
    "\n",
    "    legend = Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/legend.png\")\n",
    "\n",
    "    im_new = Image.new('RGB', (256, 296))\n",
    "    im_new.paste(legend, (0, 0))\n",
    "    im_new.paste(im, (0, 40))\n",
    "    \n",
    "    return im_new\n",
    "\n",
    "def prompt_with_mutation(user_prompt, mut_rate, fpath=None):\n",
    "    \n",
    "    #Create initial layout based on prompt\n",
    "    im, layout, output = prompt_to_layout(user_prompt)\n",
    "        \n",
    "    #Create mutated layout based on initial\n",
    "    mut_len = int((1-mut_rate)*len(layout))\n",
    "    index1 = random.randrange(0,len(layout)-mut_len)\n",
    "    rooms = layout[index1:index1+mut_len]\n",
    "    rooms = [room.lstrip().rstrip() for room in rooms]\n",
    "    shuffle(rooms)\n",
    "    rooms = ', '.join(rooms).lstrip().rstrip() + ','\n",
    "    new_prompt = '[User prompt] {} [Layout] {}'.format(user_prompt, rooms)\n",
    "    input_ids = tokenizer(new_prompt, return_tensors='pt')\n",
    "    mut_output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, temperature=0.1, max_length=300)\n",
    "    mut_output = tokenizer.batch_decode(mut_output, skip_special_tokens=True)\n",
    "    mut_im = mut_txt2layout(mut_output)\n",
    "    \n",
    "    return im, mut_im\n",
    "\n",
    "def gen_and_mutate(user_prompt, mutate=False, mut_rate=0.2):    \n",
    "    if(mutate):\n",
    "        im, mut_im = None, None\n",
    "        while (mut_im is None):\n",
    "            try:\n",
    "                im, mut_im = prompt_with_mutation(user_prompt, mut_rate, fpath=None)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        mut_im=Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/empty.png\")\n",
    "        im, _, _ = prompt_to_layout(user_prompt)\n",
    "        \n",
    "    return im, mut_im\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/gradio/routes.py\", line 394, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/gradio/blocks.py\", line 1075, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/gradio/blocks.py\", line 884, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/tmp/rame/ipykernel_472661/154678461.py\", line 146, in gen_and_mutate\n",
      "    im, _, _ = prompt_to_layout(user_prompt)\n",
      "  File \"/tmp/rame/ipykernel_472661/154678461.py\", line 60, in prompt_to_layout\n",
      "    output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, top_k=100, max_length=300)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/generation/utils.py\", line 1462, in generate\n",
      "    return self.sample(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/generation/utils.py\", line 2478, in sample\n",
      "    outputs = self(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 852, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 687, in forward\n",
      "    outputs = block(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 308, in forward\n",
      "    attn_outputs = self.attn(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 232, in forward\n",
      "    k_rot = apply_rotary_pos_emb(k_rot, sin, cos)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 79, in apply_rotary_pos_emb\n",
      "    return (tensor * cos) + (rotate_every_two(tensor) * sin)\n",
      "RuntimeError: The size of tensor a (48) must match the size of tensor b (64) at non-singleton dimension 3\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            textbox = gr.components.Textbox(placeholder='house with two bedrooms and one bathroom', lines=\"1\", \n",
    "                                        label=\"DESCRIBE YOUR DESIGN\")\n",
    "            checkbox =  gr.components.Checkbox(label='Mutate')\n",
    "            slider = gr.components.Slider(0.2, 0.8, step=0.1, label='Mutation rate')\n",
    "            generate = gr.components.Button(value=\"Generate layout\")\n",
    "        generated = gr.components.Image(label='Generated Layout')\n",
    "        mutated = gr.components.Image(label='Mutated Layout')\n",
    "    with gr.Row():\n",
    "        generate.click(gen_and_mutate, inputs=[textbox, checkbox, slider], outputs=[generated, mutated])\n",
    "    \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import gradio as gr\n",
    "from random import shuffle\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = Path(\"architext/gptj-162M\")\n",
    "finetuned = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-j-6B')\n",
    "\n",
    "def merge_images(im1, im2):\n",
    "    images = [im1, im2]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    combined = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        combined.paste(im, (x_offset,0))\n",
    "        x_offset += im.size[0]\n",
    "    return combined\n",
    "\n",
    "room_labels = {\"living_room\": 1, \"kitchen\": 2, \"bedroom\": 3, \"bathroom\": 4, \"missing\": 5, \"closet\": 6,\n",
    "                         \"balcony\": 7, \"corridor\": 8, \"dining_room\": 9, \"laundry_room\": 10}\n",
    "\n",
    "architext_colors = [[0, 0, 0], [249, 222, 182], [195, 209, 217], [250, 120, 128], [126, 202, 234], [190, 0, 198], [255, 255, 255],\n",
    "                   [6, 53, 17], [17, 33, 58], [132, 151, 246], [197, 203, 159], [6, 53, 17],]\n",
    "\n",
    "regex = re.compile(\".*?\\((.*?)\\)\")\n",
    "\n",
    "def draw_polygons(polygons, colors, im_size=(256, 256), b_color=\"white\", fpath=None):\n",
    "\n",
    "    image = Image.new(\"RGB\", im_size, color=\"white\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for poly, color, in zip(polygons, colors):\n",
    "        xy = poly.exterior.xy\n",
    "        coords = np.dstack((xy[1], xy[0])).flatten()\n",
    "        draw.polygon(list(coords), fill=(0, 0, 0))\n",
    "\n",
    "        #get inner polygon coordinates\n",
    "        small_poly = poly.buffer(-1, resolution=32, cap_style=2, join_style=2, mitre_limit=5.0)\n",
    "        if small_poly.geom_type == 'MultiPolygon':\n",
    "            mycoordslist = [list(x.exterior.coords) for x in small_poly]\n",
    "            for coord in mycoordslist:\n",
    "                coords = np.dstack((np.array(coord)[:,1], np.array(coord)[:, 0])).flatten()\n",
    "                draw.polygon(list(coords), fill=tuple(color))\n",
    "        elif poly.geom_type == 'Polygon':\n",
    "            #get inner polygon coordinates\n",
    "            xy2 = small_poly.exterior.xy\n",
    "            coords2 = np.dstack((xy2[1], xy2[0])).flatten()\n",
    "            # draw it on canvas, with the appropriate colors\n",
    "            draw.polygon(list(coords2), fill=tuple(color))\n",
    "\n",
    "    #image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "    if(fpath):\n",
    "        image.save(fpath, format='png', quality=100, subsampling=0)\n",
    "        np.save(fpath, np.array(image))\n",
    "\n",
    "    return draw, image\n",
    "\n",
    "def prompt_to_layout(user_prompt, fpath=None):\n",
    "\n",
    "    model_prompt = '[User prompt] {} [Layout]'.format(user_prompt)\n",
    "    input_ids = tokenizer(model_prompt, return_tensors='pt')\n",
    "    output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, top_k=100, max_length=300)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "    layout = output[0].split('[User prompt]')[1].split('[Layout]')[1].split(', ')\n",
    "    spaces = [txt.split(':')[0].lstrip() for txt in layout]\n",
    "    spaces = [re.sub(r'\\d+', '', s) for s in spaces]\n",
    "\n",
    "    coordinates = [txt.split(':')[1] for txt in layout]\n",
    "    coordinates = [re.findall(regex, coord) for coord in coordinates]\n",
    "\n",
    "    polygons = []\n",
    "    for coord in coordinates:\n",
    "        polygons.append([point.split(',') for point in coord])\n",
    "\n",
    "    geom = []\n",
    "    for poly in polygons:\n",
    "        geom.append(Polygon(np.array(poly, dtype=int)))\n",
    "\n",
    "    colors = [architext_colors[room_labels[space]] for space in spaces]\n",
    "\n",
    "    _, im = draw_polygons(geom, colors, fpath=fpath)\n",
    "\n",
    "    legend = Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/legend.png\")\n",
    "\n",
    "    im_new = Image.new('RGB', (256, 296))\n",
    "    im_new.paste(legend, (0, 0))\n",
    "    im_new.paste(im, (0, 40))\n",
    "\n",
    "    return im_new, layout, output\n",
    "\n",
    "def mut_txt2layout(mut_output):\n",
    "    layout = mut_output[0].split('[User prompt]')[1].split('[Layout]')[1].split(', ')\n",
    "    spaces = [txt.split(':')[0].lstrip() for txt in layout]\n",
    "    spaces = [re.sub(r'\\d+', '', s) for s in spaces]\n",
    "    coordinates = [txt.split(':')[1] for txt in layout]\n",
    "    coordinates = [re.findall(regex, coord) for coord in coordinates]\n",
    "\n",
    "    polygons = []\n",
    "    for coord in coordinates:\n",
    "        polygons.append([point.split(',') for point in coord])\n",
    "\n",
    "    geom = []\n",
    "    for poly in polygons:\n",
    "        geom.append(Polygon(np.array(poly, dtype=int)))\n",
    "\n",
    "    colors = [architext_colors[room_labels[space]] for space in spaces]\n",
    "    _, im = draw_polygons(geom, colors, fpath=None)\n",
    "\n",
    "    legend = Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/legend.png\")\n",
    "\n",
    "    im_new = Image.new('RGB', (256, 296))\n",
    "    im_new.paste(legend, (0, 0))\n",
    "    im_new.paste(im, (0, 40))\n",
    "\n",
    "    return im_new\n",
    "\n",
    "def prompt_with_mutation(user_prompt, mut_rate, fpath=None):\n",
    "\n",
    "    #Create initial layout based on prompt\n",
    "    im, layout, output = prompt_to_layout(user_prompt)\n",
    "\n",
    "    #Create mutated layout based on initial\n",
    "    mut_len = int((1-mut_rate)*len(layout))\n",
    "    index1 = random.randrange(0,len(layout)-mut_len)\n",
    "    rooms = layout[index1:index1+mut_len]\n",
    "    rooms = [room.lstrip().rstrip() for room in rooms]\n",
    "    shuffle(rooms)\n",
    "    rooms = ', '.join(rooms).lstrip().rstrip() + ','\n",
    "    new_prompt = '[User prompt] {} [Layout] {}'.format(user_prompt, rooms)\n",
    "    input_ids = tokenizer(new_prompt, return_tensors='pt')\n",
    "    mut_output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, temperature=0.1, max_length=300)\n",
    "    mut_output = tokenizer.batch_decode(mut_output, skip_special_tokens=True)\n",
    "    mut_im = mut_txt2layout(mut_output)\n",
    "\n",
    "    return im, mut_im\n",
    "\n",
    "def gen_and_mutate(user_prompt, mutate=False, mut_rate=0.2):\n",
    "    if(mutate):\n",
    "        im, mut_im = None, None\n",
    "        while (mut_im is None):\n",
    "            try:\n",
    "                im, mut_im = prompt_with_mutation(user_prompt, mut_rate, fpath=None)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        mut_im=Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/empty.png\")\n",
    "        im, _, _ = prompt_to_layout(user_prompt)\n",
    "\n",
    "    return im, mut_im\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            textbox = gr.components.Textbox(placeholder='house with two bedrooms and one bathroom', lines=\"1\",\n",
    "                                        label=\"DESCRIBE YOUR DESIGN\")\n",
    "            checkbox =  gr.components.Checkbox(label='Mutate')\n",
    "            slider = gr.components.Slider(0.2, 0.8, step=0.1, label='Mutation rate')\n",
    "            generate = gr.components.Button(value=\"Generate layout\")\n",
    "        generated = gr.components.Image(label='Generated Layout')\n",
    "        mutated = gr.components.Image(label='Mutated Layout')\n",
    "    with gr.Row():\n",
    "        generate.click(gen_and_mutate, inputs=[textbox, checkbox, slider], outputs=[generated, mutated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
