{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "It looks like the config file at '/data/rame/experiments/archi/pytorch_model.bin' is not a valid JSON file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/configuration_utils.py:658\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[39m# Load config dict\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m     config_dict \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_dict_from_json_file(resolved_config_file)\n\u001b[1;32m    659\u001b[0m     config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m commit_hash\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/configuration_utils.py:745\u001b[0m, in \u001b[0;36mPretrainedConfig._dict_from_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(json_file, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m reader:\n\u001b[0;32m--> 745\u001b[0m     text \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    746\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mloads(text)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    321\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    323\u001b[0m \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m     12\u001b[0m model_path \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39m/data/rame/experiments/archi/pytorch_model.bin\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m finetuned \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_path)\n\u001b[1;32m     14\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mEleutherAI/gpt-j-6B\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:441\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[39mif\u001b[39;00m kwargs_copy\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    439\u001b[0m         _ \u001b[39m=\u001b[39m kwargs_copy\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m     config, kwargs \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    442\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    443\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    444\u001b[0m         trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[1;32m    445\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[1;32m    446\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_copy,\n\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n\u001b[1;32m    449\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:902\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    901\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 902\u001b[0m config_dict, unused_kwargs \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    904\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/configuration_utils.py:573\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    572\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    574\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    575\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/configuration_utils.py:661\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m commit_hash\n\u001b[1;32m    660\u001b[0m \u001b[39mexcept\u001b[39;00m (json\u001b[39m.\u001b[39mJSONDecodeError, \u001b[39mUnicodeDecodeError\u001b[39;00m):\n\u001b[0;32m--> 661\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    662\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIt looks like the config file at \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mresolved_config_file\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not a valid JSON file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    663\u001b[0m     )\n\u001b[1;32m    665\u001b[0m \u001b[39mif\u001b[39;00m is_local:\n\u001b[1;32m    666\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading configuration file \u001b[39m\u001b[39m{\u001b[39;00mresolved_config_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: It looks like the config file at '/data/rame/experiments/archi/pytorch_model.bin' is not a valid JSON file."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import gradio as gr\n",
    "from random import shuffle\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = Path(\"/data/rame/experiments/archi/\")\n",
    "finetuned = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-j-6B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_images(im1, im2):\n",
    "    images = [im1, im2]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    combined = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        combined.paste(im, (x_offset,0))\n",
    "        x_offset += im.size[0]\n",
    "    return combined\n",
    "\n",
    "room_labels = {\"living_room\": 1, \"kitchen\": 2, \"bedroom\": 3, \"bathroom\": 4, \"missing\": 5, \"closet\": 6, \n",
    "                         \"balcony\": 7, \"corridor\": 8, \"dining_room\": 9, \"laundry_room\": 10}\n",
    "\n",
    "architext_colors = [[0, 0, 0], [249, 222, 182], [195, 209, 217], [250, 120, 128], [126, 202, 234], [190, 0, 198], [255, 255, 255], \n",
    "                   [6, 53, 17], [17, 33, 58], [132, 151, 246], [197, 203, 159], [6, 53, 17],]\n",
    "\n",
    "regex = re.compile(\".*?\\((.*?)\\)\")\n",
    "\n",
    "def draw_polygons(polygons, colors, im_size=(256, 256), b_color=\"white\", fpath=None):\n",
    "\n",
    "    image = Image.new(\"RGB\", im_size, color=\"white\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for poly, color, in zip(polygons, colors):\n",
    "        xy = poly.exterior.xy\n",
    "        coords = np.dstack((xy[1], xy[0])).flatten()\n",
    "        draw.polygon(list(coords), fill=(0, 0, 0))       \n",
    "        \n",
    "        #get inner polygon coordinates\n",
    "        small_poly = poly.buffer(-1, resolution=32, cap_style=2, join_style=2, mitre_limit=5.0)\n",
    "        if small_poly.geom_type == 'MultiPolygon':\n",
    "            mycoordslist = [list(x.exterior.coords) for x in small_poly]\n",
    "            for coord in mycoordslist:\n",
    "                coords = np.dstack((np.array(coord)[:,1], np.array(coord)[:, 0])).flatten()\n",
    "                draw.polygon(list(coords), fill=tuple(color)) \n",
    "        elif poly.geom_type == 'Polygon':\n",
    "            #get inner polygon coordinates\n",
    "            xy2 = small_poly.exterior.xy\n",
    "            coords2 = np.dstack((xy2[1], xy2[0])).flatten()\n",
    "            # draw it on canvas, with the appropriate colors\n",
    "            draw.polygon(list(coords2), fill=tuple(color)) \n",
    "\n",
    "    #image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "    if(fpath):\n",
    "        image.save(fpath, format='png', quality=100, subsampling=0)\n",
    "        np.save(fpath, np.array(image))\n",
    "\n",
    "    return draw, image\n",
    "\n",
    "def prompt_to_layout(user_prompt, fpath=None):\n",
    "    \n",
    "    model_prompt = '[User prompt] {} [Layout]'.format(user_prompt)\n",
    "    input_ids = tokenizer(model_prompt, return_tensors='pt')\n",
    "    output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, top_k=100, max_length=300)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    \n",
    "    layout = output[0].split('[User prompt]')[1].split('[Layout]')[1].split(', ')\n",
    "    spaces = [txt.split(':')[0].lstrip() for txt in layout]\n",
    "    spaces = [re.sub(r'\\d+', '', s) for s in spaces]\n",
    "\n",
    "    coordinates = [txt.split(':')[1] for txt in layout]\n",
    "    coordinates = [re.findall(regex, coord) for coord in coordinates]\n",
    "    \n",
    "    polygons = []\n",
    "    for coord in coordinates:\n",
    "        polygons.append([point.split(',') for point in coord])\n",
    "        \n",
    "    geom = []\n",
    "    for poly in polygons:\n",
    "        geom.append(Polygon(np.array(poly, dtype=int)))\n",
    "        \n",
    "    colors = [architext_colors[room_labels[space]] for space in spaces]\n",
    "    \n",
    "    _, im = draw_polygons(geom, colors, fpath=fpath)\n",
    "    \n",
    "    legend = Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/legend.png\")\n",
    "    \n",
    "    im_new = Image.new('RGB', (256, 296))\n",
    "    im_new.paste(legend, (0, 0))\n",
    "    im_new.paste(im, (0, 40))\n",
    "    \n",
    "    return im_new, layout, output\n",
    "\n",
    "def mut_txt2layout(mut_output):\n",
    "    layout = mut_output[0].split('[User prompt]')[1].split('[Layout]')[1].split(', ')\n",
    "    spaces = [txt.split(':')[0].lstrip() for txt in layout]\n",
    "    spaces = [re.sub(r'\\d+', '', s) for s in spaces]\n",
    "    coordinates = [txt.split(':')[1] for txt in layout]\n",
    "    coordinates = [re.findall(regex, coord) for coord in coordinates]\n",
    "\n",
    "    polygons = []\n",
    "    for coord in coordinates:\n",
    "        polygons.append([point.split(',') for point in coord])\n",
    "\n",
    "    geom = []\n",
    "    for poly in polygons:\n",
    "        geom.append(Polygon(np.array(poly, dtype=int)))\n",
    "\n",
    "    colors = [architext_colors[room_labels[space]] for space in spaces]\n",
    "    _, im = draw_polygons(geom, colors, fpath=None)\n",
    "\n",
    "    legend = Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/legend.png\")\n",
    "\n",
    "    im_new = Image.new('RGB', (256, 296))\n",
    "    im_new.paste(legend, (0, 0))\n",
    "    im_new.paste(im, (0, 40))\n",
    "    \n",
    "    return im_new\n",
    "\n",
    "def prompt_with_mutation(user_prompt, mut_rate, fpath=None):\n",
    "    \n",
    "    #Create initial layout based on prompt\n",
    "    im, layout, output = prompt_to_layout(user_prompt)\n",
    "        \n",
    "    #Create mutated layout based on initial\n",
    "    mut_len = int((1-mut_rate)*len(layout))\n",
    "    index1 = random.randrange(0,len(layout)-mut_len)\n",
    "    rooms = layout[index1:index1+mut_len]\n",
    "    rooms = [room.lstrip().rstrip() for room in rooms]\n",
    "    shuffle(rooms)\n",
    "    rooms = ', '.join(rooms).lstrip().rstrip() + ','\n",
    "    new_prompt = '[User prompt] {} [Layout] {}'.format(user_prompt, rooms)\n",
    "    input_ids = tokenizer(new_prompt, return_tensors='pt')\n",
    "    mut_output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, temperature=0.1, max_length=300)\n",
    "    mut_output = tokenizer.batch_decode(mut_output, skip_special_tokens=True)\n",
    "    mut_im = mut_txt2layout(mut_output)\n",
    "    \n",
    "    return im, mut_im\n",
    "\n",
    "def gen_and_mutate(user_prompt, mutate=False, mut_rate=0.2):    \n",
    "    if(mutate):\n",
    "        im, mut_im = None, None\n",
    "        while (mut_im is None):\n",
    "            try:\n",
    "                im, mut_im = prompt_with_mutation(user_prompt, mut_rate, fpath=None)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        mut_im=Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/empty.png\")\n",
    "        im, _, _ = prompt_to_layout(user_prompt)\n",
    "        \n",
    "    return im, mut_im\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/gradio/routes.py\", line 394, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/gradio/blocks.py\", line 1075, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/gradio/blocks.py\", line 884, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/tmp/rame/ipykernel_472661/154678461.py\", line 146, in gen_and_mutate\n",
      "    im, _, _ = prompt_to_layout(user_prompt)\n",
      "  File \"/tmp/rame/ipykernel_472661/154678461.py\", line 60, in prompt_to_layout\n",
      "    output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, top_k=100, max_length=300)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/generation/utils.py\", line 1462, in generate\n",
      "    return self.sample(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/generation/utils.py\", line 2478, in sample\n",
      "    outputs = self(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 852, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 687, in forward\n",
      "    outputs = block(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 308, in forward\n",
      "    attn_outputs = self.attn(\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 232, in forward\n",
      "    k_rot = apply_rotary_pos_emb(k_rot, sin, cos)\n",
      "  File \"/home/rame/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py\", line 79, in apply_rotary_pos_emb\n",
      "    return (tensor * cos) + (rotate_every_two(tensor) * sin)\n",
      "RuntimeError: The size of tensor a (48) must match the size of tensor b (64) at non-singleton dimension 3\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            textbox = gr.components.Textbox(placeholder='house with two bedrooms and one bathroom', lines=\"1\", \n",
    "                                        label=\"DESCRIBE YOUR DESIGN\")\n",
    "            checkbox =  gr.components.Checkbox(label='Mutate')\n",
    "            slider = gr.components.Slider(0.2, 0.8, step=0.1, label='Mutation rate')\n",
    "            generate = gr.components.Button(value=\"Generate layout\")\n",
    "        generated = gr.components.Image(label='Generated Layout')\n",
    "        mutated = gr.components.Image(label='Mutated Layout')\n",
    "    with gr.Row():\n",
    "        generate.click(gen_and_mutate, inputs=[textbox, checkbox, slider], outputs=[generated, mutated])\n",
    "    \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import gradio as gr\n",
    "from random import shuffle\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = Path(\"architext/gptj-162M\")\n",
    "finetuned = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-j-6B')\n",
    "\n",
    "def merge_images(im1, im2):\n",
    "    images = [im1, im2]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    combined = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        combined.paste(im, (x_offset,0))\n",
    "        x_offset += im.size[0]\n",
    "    return combined\n",
    "\n",
    "room_labels = {\"living_room\": 1, \"kitchen\": 2, \"bedroom\": 3, \"bathroom\": 4, \"missing\": 5, \"closet\": 6,\n",
    "                         \"balcony\": 7, \"corridor\": 8, \"dining_room\": 9, \"laundry_room\": 10}\n",
    "\n",
    "architext_colors = [[0, 0, 0], [249, 222, 182], [195, 209, 217], [250, 120, 128], [126, 202, 234], [190, 0, 198], [255, 255, 255],\n",
    "                   [6, 53, 17], [17, 33, 58], [132, 151, 246], [197, 203, 159], [6, 53, 17],]\n",
    "\n",
    "regex = re.compile(\".*?\\((.*?)\\)\")\n",
    "\n",
    "def draw_polygons(polygons, colors, im_size=(256, 256), b_color=\"white\", fpath=None):\n",
    "\n",
    "    image = Image.new(\"RGB\", im_size, color=\"white\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for poly, color, in zip(polygons, colors):\n",
    "        xy = poly.exterior.xy\n",
    "        coords = np.dstack((xy[1], xy[0])).flatten()\n",
    "        draw.polygon(list(coords), fill=(0, 0, 0))\n",
    "\n",
    "        #get inner polygon coordinates\n",
    "        small_poly = poly.buffer(-1, resolution=32, cap_style=2, join_style=2, mitre_limit=5.0)\n",
    "        if small_poly.geom_type == 'MultiPolygon':\n",
    "            mycoordslist = [list(x.exterior.coords) for x in small_poly]\n",
    "            for coord in mycoordslist:\n",
    "                coords = np.dstack((np.array(coord)[:,1], np.array(coord)[:, 0])).flatten()\n",
    "                draw.polygon(list(coords), fill=tuple(color))\n",
    "        elif poly.geom_type == 'Polygon':\n",
    "            #get inner polygon coordinates\n",
    "            xy2 = small_poly.exterior.xy\n",
    "            coords2 = np.dstack((xy2[1], xy2[0])).flatten()\n",
    "            # draw it on canvas, with the appropriate colors\n",
    "            draw.polygon(list(coords2), fill=tuple(color))\n",
    "\n",
    "    #image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "    if(fpath):\n",
    "        image.save(fpath, format='png', quality=100, subsampling=0)\n",
    "        np.save(fpath, np.array(image))\n",
    "\n",
    "    return draw, image\n",
    "\n",
    "def prompt_to_layout(user_prompt, fpath=None):\n",
    "\n",
    "    model_prompt = '[User prompt] {} [Layout]'.format(user_prompt)\n",
    "    input_ids = tokenizer(model_prompt, return_tensors='pt')\n",
    "    output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, top_k=100, max_length=300)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "    layout = output[0].split('[User prompt]')[1].split('[Layout]')[1].split(', ')\n",
    "    spaces = [txt.split(':')[0].lstrip() for txt in layout]\n",
    "    spaces = [re.sub(r'\\d+', '', s) for s in spaces]\n",
    "\n",
    "    coordinates = [txt.split(':')[1] for txt in layout]\n",
    "    coordinates = [re.findall(regex, coord) for coord in coordinates]\n",
    "\n",
    "    polygons = []\n",
    "    for coord in coordinates:\n",
    "        polygons.append([point.split(',') for point in coord])\n",
    "\n",
    "    geom = []\n",
    "    for poly in polygons:\n",
    "        geom.append(Polygon(np.array(poly, dtype=int)))\n",
    "\n",
    "    colors = [architext_colors[room_labels[space]] for space in spaces]\n",
    "\n",
    "    _, im = draw_polygons(geom, colors, fpath=fpath)\n",
    "\n",
    "    legend = Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/legend.png\")\n",
    "\n",
    "    im_new = Image.new('RGB', (256, 296))\n",
    "    im_new.paste(legend, (0, 0))\n",
    "    im_new.paste(im, (0, 40))\n",
    "\n",
    "    return im_new, layout, output\n",
    "\n",
    "def mut_txt2layout(mut_output):\n",
    "    layout = mut_output[0].split('[User prompt]')[1].split('[Layout]')[1].split(', ')\n",
    "    spaces = [txt.split(':')[0].lstrip() for txt in layout]\n",
    "    spaces = [re.sub(r'\\d+', '', s) for s in spaces]\n",
    "    coordinates = [txt.split(':')[1] for txt in layout]\n",
    "    coordinates = [re.findall(regex, coord) for coord in coordinates]\n",
    "\n",
    "    polygons = []\n",
    "    for coord in coordinates:\n",
    "        polygons.append([point.split(',') for point in coord])\n",
    "\n",
    "    geom = []\n",
    "    for poly in polygons:\n",
    "        geom.append(Polygon(np.array(poly, dtype=int)))\n",
    "\n",
    "    colors = [architext_colors[room_labels[space]] for space in spaces]\n",
    "    _, im = draw_polygons(geom, colors, fpath=None)\n",
    "\n",
    "    legend = Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/legend.png\")\n",
    "\n",
    "    im_new = Image.new('RGB', (256, 296))\n",
    "    im_new.paste(legend, (0, 0))\n",
    "    im_new.paste(im, (0, 40))\n",
    "\n",
    "    return im_new\n",
    "\n",
    "def prompt_with_mutation(user_prompt, mut_rate, fpath=None):\n",
    "\n",
    "    #Create initial layout based on prompt\n",
    "    im, layout, output = prompt_to_layout(user_prompt)\n",
    "\n",
    "    #Create mutated layout based on initial\n",
    "    mut_len = int((1-mut_rate)*len(layout))\n",
    "    index1 = random.randrange(0,len(layout)-mut_len)\n",
    "    rooms = layout[index1:index1+mut_len]\n",
    "    rooms = [room.lstrip().rstrip() for room in rooms]\n",
    "    shuffle(rooms)\n",
    "    rooms = ', '.join(rooms).lstrip().rstrip() + ','\n",
    "    new_prompt = '[User prompt] {} [Layout] {}'.format(user_prompt, rooms)\n",
    "    input_ids = tokenizer(new_prompt, return_tensors='pt')\n",
    "    mut_output = finetuned.generate(**input_ids, do_sample=True, top_p=0.94, temperature=0.1, max_length=300)\n",
    "    mut_output = tokenizer.batch_decode(mut_output, skip_special_tokens=True)\n",
    "    mut_im = mut_txt2layout(mut_output)\n",
    "\n",
    "    return im, mut_im\n",
    "\n",
    "def gen_and_mutate(user_prompt, mutate=False, mut_rate=0.2):\n",
    "    if(mutate):\n",
    "        im, mut_im = None, None\n",
    "        while (mut_im is None):\n",
    "            try:\n",
    "                im, mut_im = prompt_with_mutation(user_prompt, mut_rate, fpath=None)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        mut_im=Image.open(\"/home/rame/domainbedv2/projects/ArchitextRL/empty.png\")\n",
    "        im, _, _ = prompt_to_layout(user_prompt)\n",
    "\n",
    "    return im, mut_im\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            textbox = gr.components.Textbox(placeholder='house with two bedrooms and one bathroom', lines=\"1\",\n",
    "                                        label=\"DESCRIBE YOUR DESIGN\")\n",
    "            checkbox =  gr.components.Checkbox(label='Mutate')\n",
    "            slider = gr.components.Slider(0.2, 0.8, step=0.1, label='Mutation rate')\n",
    "            generate = gr.components.Button(value=\"Generate layout\")\n",
    "        generated = gr.components.Image(label='Generated Layout')\n",
    "        mutated = gr.components.Image(label='Mutated Layout')\n",
    "    with gr.Row():\n",
    "        generate.click(gen_and_mutate, inputs=[textbox, checkbox, slider], outputs=[generated, mutated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
